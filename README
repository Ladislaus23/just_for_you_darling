Постановка задачи:

Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых. Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. Требуется построить модель с предельно большим значением F1-меры (не меньше 0.59). Дополнительно будем измерять AUC-ROC и сравнивать её значение с F1-мерой.

Данные брались отсюда: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling

Были исследованы три модели машинного обучения: решающего дерева, случайного леса и логистической регрессии. Предварительно была проведена предобработка данных. Было проведено обучение с учётом дисбаланса классов и без него. Для избавления от дисбаланса были использованы три техники: изменение параметра class_weight='balanced', upsampling, downsampling. После применения избавления от дисбаланса результаты значительно улучшились.

Результаты моделей до избавления от дисбаланса (самое высокое значение F1-меры и AUC-ROC-меры, там где имеет смысл её считать):

Модель решающего дерева:
	F1-мера: 0.559
	AUC-ROC: 0.788

Модель случайного леса:
	F1-мера: 0.581
	AUC-ROC: 0.87

Модель логистической регрессии:
	F1-мера: 0.085
	
Результаты моделей после избавления от дисбаланса методом, показавшим наилучшие результаты:

Модель решающего дерева:
	F1-мера: 0.618
	AUC-ROC: 0.857

Модель случайного леса:
	F1-мера: 0.657
	AUC-ROC: 0.877

Модель логистической регрессии:
	F1-мера: 0.436
	
В итоге, самый хороший результат на тестовой выборке показала модель случайного леса с глубиной 8 и числом деревьев 35 при избавлении от дисбаланса методом изменения значения параметра class_weight='balanced'.
